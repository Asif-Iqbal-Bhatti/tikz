\documentclass[class=scrartcl,crop=false]{standalone}

\usepackage{graphicx,subcaption,siunitx,tikz,amsmath,cleveref}
\usetikzlibrary{positioning}

\DeclareMathOperator{\var}{var}

\begin{document}

\section{Preliminary Results}
\label{sec:preliminary-results}

\begin{figure}[htb!]
  \centering
  \begin{subfigure}[t]{0.48\linewidth}
    \begin{tikzpicture}
      \node(img){\includegraphics[width=0.95\linewidth]{Images/mse_drop}};
      \node[below=of img,yshift=1.2cm] {$n \vphantom{\var(\tilde\rho_\text{pred})}$};
      \node[left=of img,rotate=90,anchor=center,yshift=-0.9cm] {$\tilde\rho_\text{mse}$};
    \end{tikzpicture}
    \caption{Number of discarded predictions $n$ vs. mean squared error $\tilde\rho_\text{mse} = \frac{1}{N} \sum_{i=1}^N (\tilde\rho_{\text{pred},i} - \tilde\rho_{\text{exp},i})^2$}
    \label{fig:mse-drop}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.48\linewidth}
    \begin{tikzpicture}
      \node(img){\includegraphics[width=0.95\linewidth]{Images/ae_uncert}};
      \node[below=of img,yshift=1.2cm] {$\Delta \tilde\rho$};
      \node[left=of img,rotate=90,anchor=center,yshift=-0.9cm] {$\var(\tilde\rho_\text{pred})$};
    \end{tikzpicture}
    \caption{Absolute error $\Delta \tilde\rho = |\tilde\rho_\text{pred} - \tilde\rho_\text{exp}|$ vs. model uncertainty $\var(\tilde\rho_\text{pred})$}
    \label{fig:scatter}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\linewidth}
    \begin{tikzpicture}
      \node(img){\includegraphics[width=0.95\linewidth]{Images/exp_vs_pred}};
      \node[below=of img,yshift=1.2cm] {$\tilde\rho_\text{exp}$};
      \node[left=of img,rotate=90,anchor=center,yshift=-1.1cm] {$\tilde\rho_\text{pred}$};
    \end{tikzpicture}
    \caption{Experimental vs. predicted $\tilde\rho$}
    \label{fig:exp-vs-pred-norm}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.48\linewidth}
    \begin{tikzpicture}
      \node[yscale=0.95](img){\includegraphics[width=0.95\linewidth]{Images/exp_vs_pred_norm}};
      \node[below=of img,yshift=1.2cm] {$\mathcal{N}(\tilde\rho_\text{exp})$};
      \node[left=of img,rotate=90,anchor=center,yshift=-0.9cm] {$\mathcal{N}(\tilde\rho_\text{pred})$};
    \end{tikzpicture}
    \caption{Exp. vs. pred. $\tilde\rho$ normalized to $\mathcal{N}(0,1)$}
    \label{fig:exp-vs-pred}
  \end{subfigure}
  \caption{Preliminary results for predicting normalized logarithmic resistivity $\tilde\rho = \log[\rho/(\si{\ohm\centi\meter})]$}
  \label{fig:preliminary-results}
\end{figure}

\Cref{fig:preliminary-results} shows preliminary results for a neural network that combines aleatoric (observational) and epistemic (model) uncertainty estimation. It predicts the logarithm of the electrical resistivity $\log(\rho)$, which together with Seebeck coefficient $S$ and thermal conductivity $\kappa$ is one of three material properties necessary to compute the thermoelectric figure of merit ($T$ is the absolute temperature),
\begin{equation}
  zT = \frac{S^2 T}{\rho \, \kappa}.
\end{equation}
For brevity, we show results only for $\rho$ but our neural nets perform comparably on $S$ and better on $\kappa$.

In \cref{fig:mse-drop}, the mean squared error (MSE) drops off monotonically as we successively discard the model's most uncertain predictions (blue line), demonstrating that the estimated model uncertainty is strongly correlated with the error it made. The orange line was plotted by successively removing points of largest model error. It marks the ideal that would be reached if the model knew its own error perfectly.

\Cref{fig:scatter} provides evidence that our model is unlikely to predict false positives. Most points lie on or above the parity line ($y = x$). There are no points with large absolute error that the model feels certain about. Points in the top-left corner have large uncertainty despite incurring only small errors. If those materials are in fact good thermoelectrics, they would be false negatives.

\Cref{fig:exp-vs-pred,fig:exp-vs-pred-norm} show model predictions vs. experimentally measured ground truth. The error bars indicate model uncertainty, demonstrating that the model is less certain about outliers and more so in regions of material space with ample training data. \Cref{fig:exp-vs-pred} is normalised, i.e. with labels rescaled to zero-mean and unit-variance, \cref{fig:exp-vs-pred-norm} non-normalised. We see good agreement between prediction and experiment. Moreover, the uncertainty of predictions indicated by the error bars is significantly larger for outliers than for clustered data indicating that the model correctly estimates high epistemic uncertainty for those predictions.

\end{document}